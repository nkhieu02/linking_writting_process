{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/hieunguyen/.kaggle/kaggle.json'\n",
            "Downloading linking-writing-processes-to-writing-quality.zip to /home/hieunguyen/Desktop/NLP/linking_writing_process\n",
            " 97%|██████████████████████████████████████▊ | 105M/108M [00:03<00:00, 36.0MB/s]\n",
            "100%|████████████████████████████████████████| 108M/108M [00:03<00:00, 30.5MB/s]\n",
            "Archive:  linking-writing-processes-to-writing-quality.zip\n",
            "  inflating: linking-writing-processes-to-writing-quality/sample_submission.csv  \n",
            "  inflating: linking-writing-processes-to-writing-quality/test_logs.csv  \n",
            "  inflating: linking-writing-processes-to-writing-quality/train_logs.csv  \n",
            "  inflating: linking-writing-processes-to-writing-quality/train_scores.csv  \n"
          ]
        }
      ],
      "source": [
        "! kaggle competitions download -c linking-writing-processes-to-writing-quality\n",
        "! unzip linking-writing-processes-to-writing-quality.zip -d linking-writing-processes-to-writing-quality\n",
        "! rm linking-writing-processes-to-writing-quality.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from utils.data import EssayDataset, generate_batch, activities,\\\n",
        "                       df, label_df, c_feat, d_feat\n",
        "from utils.utils import train, evaluate, EarlyStopping, CosineAnnealingWarmupRestarts\n",
        "from utils.models import Grader\n",
        "\n",
        "# Define hyperparameters\n",
        "\n",
        "## Model:\n",
        "HIDDEN_DIM = 200\n",
        "LINEAR_HIDDEN_DIM = 10\n",
        "EMBEDDING_SIZE = 10\n",
        "\n",
        "## Data:\n",
        "SPLIT = 0.2\n",
        "NOF_DATA = 100\n",
        "\n",
        "## Training:\n",
        "EPOCHS = 3\n",
        "CLIP = 1\n",
        "BATCH = 10\n",
        "LR = 0.001\n",
        "DELTA = 0.001\n",
        "PATIENCE = 3\n",
        "MIN_LR = 0.001\n",
        "MAX_LR = 0.1\n",
        "\n",
        "## Create the file name to save:\n",
        "BASE_NAME = f\"rnn_H{HIDDEN_DIM}_LH{LINEAR_HIDDEN_DIM}_E{EMBEDDING_SIZE}_\" \\\n",
        "      f\"S{SPLIT}_N{NOF_DATA}_E{EPOCHS}_C{CLIP}_B{BATCH}_\" \\\n",
        "      f\"LR{LR}_D{DELTA}_P{PATIENCE}_MinLR{MIN_LR}_MaxLR{MAX_LR}\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define the data\n",
        "ids = df['id'].unique()[0:NOF_DATA]\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_ids, val_ids = train_test_split(ids, test_size = SPLIT)\n",
        "train_dataset = EssayDataset(df, train_ids, label_df, c_feat, d_feat)\n",
        "val_dataset = EssayDataset(df, val_ids, label_df, c_feat, d_feat)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = BATCH,\n",
        "                        collate_fn = generate_batch)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size = BATCH,\n",
        "                        collate_fn = generate_batch)\n",
        "\n",
        "# Define model for training\n",
        "class_size_dict = {'activity': len(activities)}\n",
        "model = Grader(HIDDEN_DIM, LINEAR_HIDDEN_DIM, class_size_dict,\n",
        "               EMBEDDING_SIZE, c_feat, d_feat).to(device)\n",
        "training_steps = EPOCHS * len(train_dataloader)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LR)\n",
        "early_stop = EarlyStopping(patience= PATIENCE, delta= DELTA, file_name= f'{BASE_NAME}.pt')\n",
        "lr_scheduler = CosineAnnealingWarmupRestarts(optimizer, training_steps, min_lr = MIN_LR, \n",
        "                                             max_lr= MAX_LR, warmup_steps= int(training_steps * 0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-0C2KnzZYPWW",
        "outputId": "21115507-d530-416d-a611-6524294739a9"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "\n",
        "\n",
        "    train_loss = train(model, train_dataloader, val_dataloader,optimizer, criterion, CLIP,\n",
        "                       evaluate, early_stop, BASE_NAME)\n",
        "    valid_loss = evaluate(model, val_dataloader, criterion)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}') # 0.723"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
